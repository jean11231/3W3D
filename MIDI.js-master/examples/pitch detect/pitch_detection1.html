

<html>
<head>
	<link rel="stylesheet" type="text/css" href="https://edgeportal.blob.core.windows.net/media/demotemplate.css">
</head>

<body>
	<!-- DEMO CONTENT -->
	<section class="section section--banner section--banner--light section--tuner">
		<div class="container">
			<h2 class="visually-hidden">Tuner</h2>
			<div class="section__body tuner__body">
				<div class="layout layout--basic">
				<div class="module module--secondary">
					<div class="tuner__gauge-wrap">
						<div class="tuner__values clear">
	                        <div class="tuner__value">
	                        	<h5>Pitch</h5>
								<span class="subtitle" id="pitch">-- Hz</span>
	                        </div>
	                        <div class="tuner__value">
	                        	<h5>Cents</h5>
								<span class="subtitle" id="cents"></span>
	                        </div>
	                        <div class="tuner__value">
	                        	<h5>Note</h5>
								<span class="subtitle" id="note">--</span>
	                        </div>
	                    </div>
	                    <canvas class="tuner__gauge" id="gaugeCanvas"></canvas>
					</div>
				</div>
				<div class="module module--primary">
					<p class="alert--error tuner__alert" id="errorMessage"></p>
					<div class="tuner__controls">
						<h3 class="subtitle">Tune using:</h3>
	                    <button class="button tuner__input-button" id="micButton">Microphone</button>
	                    <button class="button tuner__input-button" id="refButton">Reference tone</button>
											<!--div id="microphoneOptions" class="tuner__options">
	                        <fieldset>
	                            <legend class="subtitle">Base frequency</legend>
	                            <button class="button tuner__options__button minusFreq">-</button>
	                            <button class="button tuner__options__button plusFreq">+</button>
	                        </fieldset>
	                    </div-->
	                    <div id="referenceOptions" class="tuner__options">
	                        <fieldset>
	                            <legend class="subtitle">Base frequency</legend>
	                            <button class="button tuner__options__button minusFreq">-</button>
	                            <button class="button tuner__options__button plusFreq">+</button>
	                        </fieldset>
	                        <fieldset>
	                            <legend class="subtitle">Note</legend>
	                            <button class="button tuner__options__button" id="minusRefNote">-</button>
	                            <button class="button tuner__options__button" id="plusRefNote">+</button>
	                        </fieldset>
	                    </div>
					</div>
				</div>
			</div>
			</div>
		</div>
	</section>
<output id="out"></output>
<script type="text/javascript" src="https://code.jquery.com/jquery-2.1.3.min.js"></script>
<script type="text/javascript" src="https://bernii.github.io/gauge.js/dist/gauge.min.js"></script>

<script>
/* global $, Gauge */
var tempBuffer = [];
var eventArray = [];
var beat = 0;
var dOrU = 'D';
var fps = 0;
window.countFPS = (function () {
  var lastLoop = (new Date()).getMilliseconds();
  var count = 1;
  fps = 0;

  return function () {
    var currentLoop = (new Date()).getMilliseconds();
    if (lastLoop > currentLoop) {
      fps = count;
      count = 1;
    } else {
      count += 1;
    }
    lastLoop = currentLoop;
    return fps;
  };
}());

var $out = $('#out');
(function loop() {
    requestAnimationFrame(function () {
      $out.html(countFPS());
      loop();
    });
}());
function Event (beat, duration, note, type, volume, pos) {
	/*  this.beat = beat || 0.0;
	this.duration = duration || 1.0; // default: quarter note
	this.note = note || 69; // default: (A4, 69)
	this.type = type || 'D'; // default: Down bow
	this.pos = position || 0.5; // default: middle bow
	this.length =  (volume+duration)/2|| 0.3; // default: 0.3
	if((volume+duration)/2>1)this.length = 1;
	this.volume = volume || 127;
	this.string = notetoString(note);
	console.log(notetoString(note));*/

	this.beat = beat;
	this.duration = duration; // default: 1 QN
	this.note = note; // default: (A4, 69)

	// if note == 0 ... this is a rest

	// default or running parameters
	Event.type = Event.type === undefined ? 'D' : Event.type;
	if (type === undefined) {   // not given, use the previous type
	if (note !== 0) this.type = Event.type; // for note only
	} else {
	this.type = type;
	Event.type = type;
	}

	Event.volume = Event.volume === undefined ? 0.5 : Event.volume;
	if (volume === undefined) {
	this.volume = Event.volume;
	} else {
	this.volume = volume;
	Event.volume = volume;
	}

	Event.pos = Event.pos === undefined ? 0.5 : Event.pos;
	if (pos === undefined) {
	this.pos = Event.pos;
	} else {
	this.pos = pos;
	Event.pos = pos;
	}

	this.string = notetoString(note);

	this.length = dynamic2Length (this.volume, this.pos, this.duration);
}
function dynamic2Length (dynamic, bowCenter, duration) {

	// 0. extra long stroke ... return 1.0

	// 1. consider duration (2 beats <--> 1.0)

	var len = Math.min (duration/2, 1.0);

	// 2. consider dynamics
	len = len * dynamic;

	console.log ('dy:' + dynamic + ' len: ' + len);

	return len;

}
function notetoString(note){
	if(note>55&&note<62)return 'G';
	if(note>=62&&note<69)return 'D';
	if(note>=69&&note<76)return 'A';
	if(note>=76)return 'E';
}
function noteToMidi(note){
	if(note=='G3') return 55;
	if(note=='G#3') return 56;
	if(note=='A3') return 57;
	if(note=='A#3') return 58;
	if(note=='B3') return 59;
	if(note=='C4') return 60;
	if(note=='C#4') return 61;
	if(note=='D4') return 62;
	if(note=='D#4') return 63;
	if(note=='E4') return 64;
	if(note=='F4') return 65;
	if(note=='F#4') return 66;
	if(note=='G4') return 67;
	if(note=='G#4') return 68;
	if(note=='A4') return 69;
	if(note=='A#4') return 70;
	if(note=='B4') return 71;
	if(note=='C5') return 72;
	if(note=='C#5') return 73;
	if(note=='D5') return 74;
	if(note=='D#5') return 75;
	if(note=='E5') return 76;
	if(note=='F5') return 77;
	if(note=='F#5') return 78;
	if(note=='G5') return 79;
	if(note=='G#5') return 80;
	if(note=='A5') return 81;
	if(note=='A#5') return 82;
	if(note=='B5') return 83;
	if(note=='C6') return 84;
	if(note=='C#6') return 85;
	if(note=='D6') return 86;
	if(note=='D#6') return 87;
	if(note=='E6') return 88;
	if(note=='F6') return 89;
	if(note=='F#6') return 90;
	if(note=='G6') return 91;
	if(note=='G#6') return 92;
	if(note=='A6') return 93;
	if(note=='A#6') return 94;
	if(note=='B6') return 95;
	if(note=='C7') return 96;
	if(note=='C#7') return 97;
	if(note=='D7') return 98;
	if(note=='D#7') return 99;
	if(note=='E7') return 100;
	if(note=='F7') return 101;
	if(note=='F#7') return 102;
	if(note=='G7') return 103;
	if(note=='G#7') return 104;
	if(note=='A7') return 105;
	if(note=='A#7') return 106;
	if(note=='B7') return 107;
	if(note=='C8') return 108;
	if(note=='C#8') return 109;
	if(note=='D8') return 110;
	if(note=='D#8') return 111;
	if(note=='E8') return 112;
	if(note=='F8') return 113;
	if(note=='F#8') return 114;
	if(note=='G8') return 115;
	if(note=='G#8') return 116;
}
$(document).ready(function () {
	var baseFreq = 440;
	var currentNoteIndex = 57; // A4
	var isRefSoundPlaying = false;
	var isMicrophoneInUse = false;
	var frameId,
		freqTable,
		gauge,
		micStream,
		notesArray,
		audioContext,
		sourceAudioNode,
		analyserAudioNode;



	var isAudioContextSupported = function () {
		// This feature is still prefixed in Safari
		window.AudioContext = window.AudioContext || window.webkitAudioContext;
		if (window.AudioContext) {
			return true;
		}
		else {
			return false;
		}
	};

	var reportError = function (message) {
		$('#errorMessage').html(message).show();
	};

	var init = function () {

		$.getJSON('notes.json', function (data) {
			freqTable = data;
		});

		$('.tuner__options').toggle(false);

		var gaugeCanvas = $('#gaugeCanvas')[0];
		gauge = new Gauge(gaugeCanvas).setOptions({
			strokeColor: '#dedede',
			pointer: {
				length: 0.8,
				strokeWidth: 0.035
			},
			angle: 0,
			lineWidth: 0.30,
			fontSize: 30,
			limitMax: true
		});
		gauge.maxValue = 100;

		// This gauge control does not look good in all browsers if set to 0 from the beginning.
		// Setting it to 1 and then to 0 solves this.
		gauge.set(1);
		gauge.set(0);

		if (isAudioContextSupported()) {
			audioContext = new window.AudioContext();
		}
		else {
			reportError('AudioContext is not supported in this browser');
		}
	};

	var updatePitch = function (pitch) {
		$('#pitch').text(pitch + ' Hz');
	};

	var updateNote = function (note) {
		$('#note').text(note);
	};

	var updateCents = function (cents) {
		// We may get negative values here.
		// Add 50 cents to what we get
		gauge.set(cents + 50);
		$('#cents').text(cents);
	};

	var isGetUserMediaSupported = function () {
		navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia;
		if ((navigator.mediaDevices && navigator.mediaDevices.getUserMedia) || navigator.getUserMedia) {
			return true;
		}

		return false;
	};

	var findFundamentalFreq = function (buffer, sampleRate) {
		// We use Autocorrelation to find the fundamental frequency.

		// In order to correlate the signal with itself (hence the name of the algorithm), we will check two points 'k' frames away.
		// The autocorrelation index will be the average of these products. At the same time, we normalize the values.
		// Source: http://www.phy.mty.edu/~suits/autocorrelation.html
		// Assuming the sample rate is 48000Hz, a 'k' equal to 1000 would correspond to a 48Hz signal (48000/1000 = 48),
		// while a 'k' equal to 8 would correspond to a 6000Hz one, which is enough to cover most (if not all)
		// the notes we have in the notes.json file.
		var n = 1024;
		var bestK = -1;
		var bestR = 0;
		for (var k = 8; k <= 1000; k++) {
			var sum = 0;

			for (var i = 0; i < n; i++) {
				sum += ((buffer[i] - 128) / 128) * ((buffer[i + k] - 128) / 128);
			}

			var r = sum / (n + k);

			if (r > bestR) {
				bestR = r;
				bestK = k;
			}

			if (r > 0.9) {
				// Let's assume that this is good enough and stop right here
				break;
			}
		}

		if (bestR > 0.0025) {
			// The period (in frames) of the fundamental frequency is 'bestK'. Getting the frequency from there is trivial.
			var fundamentalFreq = sampleRate / bestK;
			return fundamentalFreq;
		}
		else {
			// We haven't found a good correlation
			return -1;
		}
	};

	var findClosestNote = function (freq, notes) {
		// Use binary search to find the closest note
		var low = -1;
		var high = notes.length;
		while (high - low > 1) {
			var pivot = Math.round((low + high) / 2);
			if (notes[pivot].frequency <= freq) {
				low = pivot;
			} else {
				high = pivot;
			}
		}

		if (Math.abs(notes[high].frequency - freq) <= Math.abs(notes[low].frequency - freq)) {
			// notes[high] is closer to the frequency we found
			return notes[high];
		}

		return notes[low];
	};

	var findCentsOffPitch = function (freq, refFreq) {
		// We need to find how far freq is from baseFreq in cents
		var log2 = 0.6931471805599453; // Math.log(2)
		var multiplicativeFactor = freq / refFreq;

		// We use Math.floor to get the integer part and ignore decimals
		var cents = Math.floor(1200 * (Math.log(multiplicativeFactor) / log2));
		return cents;
	};

	var detectPitch = function () {
		var buffer = new Uint8Array(analyserAudioNode.fftSize);
		analyserAudioNode.getByteTimeDomainData(buffer);

		var fundalmentalFreq = findFundamentalFreq(buffer, audioContext.sampleRate);

		if(fundalmentalFreq ==-1 && tempBuffer.length!==0){
			var dur = (tempBuffer.length-1)/fps;
			dur = (Math.round(dur * 4) / 4).toFixed(2);
			//console.log(dur);
			//console.log(tempBuffer);
			var notesInfo = [];
			if(dur>0.25){
				var midiNote = noteToMidi(tempBuffer[Math.floor((tempBuffer.length+1)/2)]);
			
				eventArray.push(new Event(beat, dur, midiNote, dOrU, 0.8, 0.5) );
				beat+=Number(dur);
				if(dOrU =='D') dOrU = 'U';
				else dOrU = 'D';
			}


			console.log(eventArray);
			/////////////////////////////////
			//var eventArray = [];
		  //eventArray.push(new Event(0, 1, note.noteN, 'D', 0.8, 0.5) );



			tempBuffer = [];
		}

		if (fundalmentalFreq !== -1) {
			var note = findClosestNote(fundalmentalFreq, notesArray);
			var cents = findCentsOffPitch(fundalmentalFreq, note.frequency);
			updateNote(note.note);
			updateCents(cents);
			tempBuffer.push(note.note);

		}

		else {
			updateNote('--');
			updateCents(-50);
		}

		frameId = window.requestAnimationFrame(detectPitch);

	};

	var streamReceived = function (stream) {
		micStream = stream;

		analyserAudioNode = audioContext.createAnalyser();
		analyserAudioNode.fftSize = 2048;

		sourceAudioNode = audioContext.createMediaStreamSource(micStream);
		sourceAudioNode.connect(analyserAudioNode);

		detectPitch();
	};

	var turnOffReferenceSound = function () {
		sourceAudioNode.stop();
		sourceAudioNode = null;
		updatePitch('--');
		updateNote('--');
		$('#referenceOptions').toggle(false);
		isRefSoundPlaying = false;
	};

	var turnOffMicrophone = function () {
		if (sourceAudioNode && sourceAudioNode.mediaStream && sourceAudioNode.mediaStream.stop) {
			sourceAudioNode.mediaStream.stop();
		}
		sourceAudioNode = null;
		updatePitch('--');
		updateNote('--');
		updateCents(-50);
		$('#microphoneOptions').toggle(false);
		analyserAudioNode = null;
		window.cancelAnimationFrame(frameId);
		isMicrophoneInUse = false;
	};

	var toggleMicrophone = function () {
		if (isRefSoundPlaying) {
			turnOffReferenceSound();
		}

		if (!isMicrophoneInUse) {
			$('#microphoneOptions').toggle(true);

			if (isGetUserMediaSupported()) {
				notesArray = freqTable[baseFreq.toString()];

				var getUserMedia = navigator.mediaDevices && navigator.mediaDevices.getUserMedia ?
					navigator.mediaDevices.getUserMedia.bind(navigator.mediaDevices) :
					function (constraints) {
						return new Promise(function (resolve, reject) {
							navigator.getUserMedia(constraints, resolve, reject);
						});
					};

				getUserMedia({audio: true}).then(streamReceived).catch(reportError);
				updatePitch(baseFreq);
				isMicrophoneInUse = true;
			}
			else {
				reportError('It looks like this browser does not support getUserMedia. ' +
				'Check <a href="http://caniuse.com/#feat=stream">http://caniuse.com/#feat=stream</a> for more info.');
			}
		}
		else {
			turnOffMicrophone();
		}
	};

	var toggleReferenceSound = function () {
		if (isMicrophoneInUse) {
			toggleMicrophone();
		}

		if (!isRefSoundPlaying) {
			$('#referenceOptions').toggle(true);
			notesArray = freqTable[baseFreq];
			sourceAudioNode = audioContext.createOscillator();
			sourceAudioNode.frequency.value = notesArray[currentNoteIndex].frequency;
			sourceAudioNode.connect(audioContext.destination);
			sourceAudioNode.start();
			updatePitch(notesArray[currentNoteIndex].frequency);
			updateNote(notesArray[currentNoteIndex].note);
			isRefSoundPlaying = true;
		} else {
			turnOffReferenceSound();
		}
	};

	var changeBaseFreq = function (delta) {
		var newBaseFreq = baseFreq + delta;
		if (newBaseFreq >= 432 && newBaseFreq <= 446) {
			baseFreq = newBaseFreq;
			notesArray = freqTable[baseFreq.toString()];
			updatePitch(baseFreq);

			if (isRefSoundPlaying) {
				// Only change the frequency if we are playing a reference sound, since
				// sourceAudioNode will be an instance of OscillatorNode
				var newNoteFreq = notesArray[currentNoteIndex].frequency;
				sourceAudioNode.frequency.value = newNoteFreq;
			}
		}
	};

	var changeReferenceSoundNote = function (delta) {
		if (isRefSoundPlaying) {
			var newNoteIndex = currentNoteIndex + delta;
			if (newNoteIndex >= 0 && newNoteIndex < notesArray.length) {
				currentNoteIndex = newNoteIndex;
				var newNoteFreq = notesArray[currentNoteIndex].frequency;
				sourceAudioNode.frequency.value = newNoteFreq;
				// In this case we haven't changed the base frequency, so we just need to update the note on screen
				updateNote(notesArray[currentNoteIndex].note);
			}
		}
	};

	var baseFreqChangeHandler = function (event) {
		changeBaseFreq(event.data);
	};

	var referenceSoundNoteHandler = function (event) {
		changeReferenceSoundNote(event.data);
	};

	$('#refButton').click(toggleReferenceSound);
	$('#micButton').click(toggleMicrophone);
	$('.minusFreq').click(-2, baseFreqChangeHandler);
	$('.plusFreq').click(2, baseFreqChangeHandler);
	$('#minusRefNote').click(-1, referenceSoundNoteHandler);
	$('#plusRefNote').click(1, referenceSoundNoteHandler);

	init();
});

</script>
</body>
</html>
